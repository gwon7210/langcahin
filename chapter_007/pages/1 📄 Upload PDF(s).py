import fitz  # PyMuPDF
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

###### dotenv ã‚’åˆ©ç”¨ã—ãªã„å ´åˆã¯æ¶ˆã—ã¦ãã ã•ã„ ######
# dotenvë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ì‚­ì œí•˜ì„¸ìš”
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


def init_page():
    st.set_page_config(
        page_title="Upload PDF(s)",
        page_icon="ğŸ“„"
    )
    st.sidebar.title("ì˜µì…˜")


def init_messages():
    clear_button = st.sidebar.button("DB ì´ˆê¸°í™”", key="clear")
    if clear_button and "vectorstore" in st.session_state:
        del st.session_state.vectorstore


def get_pdf_text():
    # file_uploaderë¡œ PDFë¥¼ ì—…ë¡œë“œí•œë‹¤
    # (file_uploaderì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ 6ì¥ì„ ì°¸ê³ í•˜ì„¸ìš”)
    pdf_file = st.file_uploader(
        label='PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” ğŸ˜‡',
        type='pdf'  # PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥
    )
    if pdf_file:
        pdf_text = ""
        with st.spinner("PDF ë¡œë”© ì¤‘ ..."):
            # PyMuPDFë¡œ PDFë¥¼ ì½ì–´ë“¤ì¸ë‹¤
            # (ìì„¸í•œ ì„¤ëª…ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”)
            pdf_doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
            for page in pdf_doc:
                pdf_text += page.get_text()

        # RecursiveCharacterTextSplitterë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• 
        # (ìì„¸í•œ ì„¤ëª…ì€ 6ì¥ì„ ì°¸ê³ í•˜ì„¸ìš”)
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            model_name="text-embedding-3-small",
            # ì ì ˆí•œ chunk sizeëŠ” PDF ì¢…ë¥˜ì— ë”°ë¼ ì¡°ì •ì´ í•„ìš”
            # ë„ˆë¬´ í¬ê²Œ ì„¤ì •í•˜ë©´ ì—¬ëŸ¬ ìœ„ì¹˜ì˜ ì •ë³´ë¥¼ ì°¸ì¡°í•˜ê¸° ì–´ë ¤ì›Œì§
            # ë„ˆë¬´ ì‘ìœ¼ë©´ í•˜ë‚˜ì˜ ì²­í¬ì— ì¶©ë¶„í•œ ë¬¸ë§¥ì´ ë“¤ì–´ê°€ì§€ ì•ŠìŒ
            chunk_size=500,
            chunk_overlap=0,
        )
        return text_splitter.split_text(pdf_text)
    else:
        return None


def build_vector_store(pdf_text):
    with st.spinner("ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì¤‘ ..."):
        if 'vectorstore' in st.session_state:
            st.session_state.vectorstore.add_texts(pdf_text)
        else:
            # ë²¡í„° DB ì´ˆê¸°í™”ì™€ ë¬¸ì„œ ì¶”ê°€ë¥¼ ë™ì‹œì— ìˆ˜í–‰
            # LangChainì˜ Document Loaderë¥¼ ì‚¬ìš©í•  ê²½ìš° `from_documents` ì‚¬ìš©
            st.session_state.vectorstore = FAISS.from_texts(
                pdf_text,
                OpenAIEmbeddings(model="text-embedding-3-small")
            )

            # FAISS ê¸°ë³¸ ì„¤ì •ì€ L2 ê±°ë¦¬
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ì²˜ëŸ¼ ì„¤ì •
            # from langchain_community.vectorstores.utils import DistanceStrategy
            # st.session_state.vectorstore = FAISS.from_texts(
            #     pdf_text,
            #     OpenAIEmbeddings(model="text-embedding-3-small"),
            #     distance_strategy=DistanceStrategy.COSINE
            # )


def page_pdf_upload_and_build_vector_db():
    st.title("PDF ì—…ë¡œë“œ ğŸ“„")
    pdf_text = get_pdf_text()
    if pdf_text:
        build_vector_store(pdf_text)


def main():
    init_page()
    page_pdf_upload_and_build_vector_db()


if __name__ == '__main__':
    main()


# ë³´ì™„ ì‚¬í•­
# ë°±í…Œ ë°ì´í„°ë² ì´ìŠ¤ì— ëŒ€í•œ ê°œë… ì¶”ê°€
# text-embedding-3-small ë§ê³ ë„ ì •ë³´ ì¶”ê°€
