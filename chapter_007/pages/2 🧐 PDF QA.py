import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

###### dotenv ã‚’åˆ©ç”¨ã—ãªã„å ´åˆã¯æ¶ˆã—ã¦ãã ã•ã„ ######
# dotenvë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ì‚­ì œí•˜ì„¸ìš”
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


def init_page():
    st.set_page_config(
        page_title="Ask My PDF(s)",
        page_icon="ğŸ§"
    )
    st.sidebar.title("ì˜µì…˜")


def select_model(temperature=0):
    models = ("GPT-3.5", "GPT-4", "Claude 3.5 Sonnet", "Gemini 1.5 Pro")
    model = st.sidebar.radio("ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:", models)
    if model == "GPT-3.5":
        return ChatOpenAI(
            temperature=temperature,
            model_name="gpt-3.5-turbo"
        )
    elif model == "GPT-4":
        return ChatOpenAI(
            temperature=temperature,
            model_name="gpt-4o"
        )
    elif model == "Claude 3.5 Sonnet":
        return ChatAnthropic(
            temperature=temperature,
            model_name="claude-3-5-sonnet-20240620"
        )
    elif model == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(
            temperature=temperature,
            model="gemini-1.5-pro-latest"
        )


def init_qa_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_template("""
    ì•„ë˜ì˜ ì „ì œ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.

    ===
    ì „ì œ ì§€ì‹
    {context}

    ===
    ì‚¬ìš©ì ì§ˆë¬¸
    {question}
    """)
    retriever = st.session_state.vectorstore.as_retriever(
        # "mmr", "similarity_score_threshold" ë“±ë„ ì‚¬ìš© ê°€ëŠ¥
        search_type="similarity",
        # ëª‡ ê°œì˜ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¬ì§€ (ê¸°ë³¸ê°’: 4)
        search_kwargs={"k": 10}
    )
    chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return chain


def page_ask_my_pdf():
    chain = init_qa_chain()

    if query := st.text_input("PDFì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ", key="input"):
        st.markdown("## ë‹µë³€")
        st.write_stream(chain.stream(query))


def main():
    init_page()
    st.title("PDF QA ğŸ§")
    if "vectorstore" not in st.session_state:
        st.warning("ë¨¼ì € ğŸ“„ Upload PDF(s)ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”")
    else:
        page_ask_my_pdf()


if __name__ == '__main__':
    main()
