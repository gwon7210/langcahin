# GitHub: https://github.com/naotaka1128/llm_app_codes/chapter_009/main.py
import streamlit as st
from langchain_classic.agents import create_tool_calling_agent, AgentExecutor
from langchain_classic.memory import ConversationBufferWindowMemory
from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_community.callbacks import StreamlitCallbackHandler

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# custom tools
from tools.search_ddg import search_ddg
from tools.fetch_page import fetch_page

###### dotenvë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ì‚­ì œí•˜ì„¸ìš” ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


CUSTOM_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì¸í„°ë„·ì—ì„œ ì •ë³´ë¥¼ ì¡°ì‚¬í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì¡°ì‚¬í•œ ì •ë³´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì´ë¯¸ ì•Œê³  ìˆëŠ” ì •ë³´ë§Œìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ê³ , ê°€ëŠ¥í•œ í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œ ë’¤ ë‹µë³€í•´ì£¼ì„¸ìš”.
(ì‚¬ìš©ìê°€ ì½ì„ í˜ì´ì§€ë¥¼ ì§€ì •í•˜ëŠ” ë“± íŠ¹ë³„í•œ ê²½ìš°ëŠ” ê²€ìƒ‰í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.)

ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ë§Œ í™•ì¸í–ˆì„ ë•Œ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨ë˜ë©´ ë‹¤ìŒ ì˜µì…˜ì„ ê³ ë ¤í•´ ì‹œë„í•´ ì£¼ì„¸ìš”.

- ê²€ìƒ‰ ê²°ê³¼ì˜ ë§í¬ë¥¼ í´ë¦­í•´ ê° í˜ì´ì§€ì˜ ì½˜í…ì¸ ë¥¼ ì—´ëŒí•˜ê³  ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.
- í•œ í˜ì´ì§€ê°€ ë„ˆë¬´ ê¸¸ ê²½ìš°, 3í˜ì´ì§€ ì´ìƒ ìŠ¤í¬ë¡¤í•˜ì§€ ë§ˆì„¸ìš” (ë©”ëª¨ë¦¬ ë¶€ë‹´ ë•Œë¬¸).
- ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë³€ê²½í•œ ë’¤ ë‹¤ì‹œ ê²€ìƒ‰ì„ ì‹œë„í•˜ì„¸ìš”.
- ê²€ìƒ‰í•  ì£¼ì œì— ë”°ë¼ ê²€ìƒ‰ ì–¸ì–´ë¥¼ ì ì ˆí•˜ê²Œ ë³€ê²½í•˜ì„¸ìš”.
  - ì˜ˆ: í”„ë¡œê·¸ë˜ë° ê´€ë ¨ ì§ˆë¬¸ì€ ì˜ì–´ë¡œ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ ë” ìœ ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ìëŠ” ë§¤ìš° ë°”ì˜ë©°, ë‹¹ì‹ ë§Œí¼ ì—¬ìœ ë¡­ì§€ ì•ŠìŠµë‹ˆë‹¤.
ë”°ë¼ì„œ ì‚¬ìš©ìì˜ ìˆ˜ê³ ë¥¼ ëœì–´ì£¼ê¸° ìœ„í•´ **ì§ì ‘ì ì¸ ë‹µë³€**ì„ ì œê³µí•´ì£¼ì„¸ìš”.

=== ë‚˜ìœ ë‹µë³€ ì˜ˆì‹œ ===
- ë‹¤ìŒ í˜ì´ì§€ë“¤ì„ ì°¸ê³ í•˜ì„¸ìš”.
- ì´ í˜ì´ì§€ë“¤ì„ ë³´ê³  ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë‹¤ìŒ í˜ì´ì§€ê°€ ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.

=== ì¢‹ì€ ë‹µë³€ ì˜ˆì‹œ ===
- ì´ ë¬¸ì œì˜ í•´ê²° ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. -- ì—¬ê¸° ì½”ë“œ ì œì‹œ --
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. -- ì—¬ê¸° ë‹µë³€ ì œì‹œ --

ë‹µë³€ ë§ˆì§€ë§‰ì—ëŠ” **ì°¸ì¡°í•œ í˜ì´ì§€ì˜ URLì„ ë°˜ë“œì‹œ ê¸°ì¬**í•´ì£¼ì„¸ìš”.
(ì‚¬ìš©ìê°€ ì •ë³´ë¥¼ ê²€ì¦í•  ìˆ˜ ìˆë„ë¡)

ì‚¬ìš©ìê°€ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ í•œêµ­ì–´ë¡œ, ìŠ¤í˜ì¸ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ ìŠ¤í˜ì¸ì–´ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
"""


def init_page():
    st.set_page_config(
        page_title="Web Browsing Agent",
        page_icon="ğŸ¤—"
    )
    st.header("Web Browsing Agent ğŸ¤—")
    st.sidebar.title("Options")


def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì´ë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"}
        ]
        st.session_state['memory'] = ConversationBufferWindowMemory(
            return_messages=True,
            memory_key="chat_history",
            k=10
        )
        # ì•„ë˜ì™€ ê°™ì´ë„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        # from langchain_community.chat_message_histories import StreamlitChatMessageHistory
        # msgs = StreamlitChatMessageHistory(key="special_app_key")
        # st.session_state['memory'] = ConversationBufferMemory(memory_key="history", chat_memory=msgs)


def select_model():
    models = ("GPT-4", "Claude 3.5 Sonnet", "Gemini 1.5 Pro", "GPT-3.5 (not recommended)")
    model = st.sidebar.radio("Choose a model:", models)
    if model == "GPT-3.5 (not recommended)":
        return ChatOpenAI(
            temperature=0, model_name="gpt-3.5-turbo")
    elif model == "GPT-4":
        return ChatOpenAI(
            temperature=0, model_name="gpt-4o")
    elif model == "Claude 3.5 Sonnet":
        return ChatAnthropic(
            temperature=0, model_name="claude-3-5-sonnet-20240620")
    elif model == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(
            temperature=0, model="gemini-1.5-pro-latest")


def create_agent():
    tools = [search_ddg, fetch_page]
    prompt = ChatPromptTemplate.from_messages([
        ("system", CUSTOM_SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    llm = select_model()
    agent = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        memory=st.session_state['memory']
    )


def main():
    init_page()
    init_messages()
    web_browsing_agent = create_agent()

    for msg in st.session_state['memory'].chat_memory.messages:
        st.chat_message(msg.type).write(msg.content)

    if prompt := st.chat_input(placeholder="2023 FIFA ì—¬ì ì›”ë“œì»µ ìš°ìŠ¹ êµ­ê°€ëŠ”?"):
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            # ì½œë°± í•¨ìˆ˜ ì„¤ì • (ì—ì´ì „íŠ¸ ë™ì‘ ì‹œê°í™”ìš©)
            st_cb = StreamlitCallbackHandler(
                st.container(), expand_new_thoughts=True)

            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            response = web_browsing_agent.invoke(
                {'input': prompt},
                config=RunnableConfig({'callbacks': [st_cb]})
            )
            st.write(response["output"])


if __name__ == '__main__':
    main()
