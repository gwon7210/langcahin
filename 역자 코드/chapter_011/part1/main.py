

import re
import streamlit as st
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_community.callbacks import StreamlitCallbackHandler

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# custom tools
from src.code_interpreter import CodeInterpreterClient
from tools.code_interpreter import code_interpreter_tool

###### dotenvë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ì‚­ì œí•´ ì£¼ì„¸ìš” ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


@st.cache_data
def load_system_prompt(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()


def csv_upload():
    with st.form("my-form", clear_on_submit=True):
        file = st.file_uploader(
            label='Upload your CSV hereğŸ˜‡',
            type='csv'
        )
        submitted = st.form_submit_button("Upload CSV")

        # session_state ì´ˆê¸°í™” ë³´ì¥
        if "uploaded_files" not in st.session_state:
            st.session_state.uploaded_files = []

        if submitted and file is not None:
            if file.name not in st.session_state.uploaded_files:
                file_bytes = file.read()
                if not file_bytes:
                    st.error("âš ï¸ ì—…ë¡œë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ã€‚")
                    return

                assistant_api_file_id = st.session_state.code_interpreter_client.upload_file(file_bytes)

                st.session_state.custom_system_prompt += \
                    f"\ì—…ë¡œë“œí•œ íŒŒì¼ ì´ë¦„: {file.name} (Code Interpreterã§ã®path: /mnt/data/{assistant_api_file_id})\n"
                st.session_state.uploaded_files.append(file.name)
        elif submitted:
            st.write("ë¶„ì„í•˜ê³  ì‹¶ì€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")

    if st.session_state.uploaded_files:
        st.sidebar.markdown("## Uploaded files:")
        for file_name in st.session_state.uploaded_files:
            st.sidebar.markdown(f"- {file_name}")


def init_page():
    st.set_page_config(
        page_title="Data Analysis Agent",
        page_icon="ğŸ¤—"
    )
    st.header("Data Analysis Agent ğŸ¤—", divider='rainbow')
    st.sidebar.title("Options")

	# message ì´ˆê¸°í™” / python runtime ì´ˆê¸°í™”
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = []
		# ëŒ€í™”ê°€ ë¦¬ì…‹ë  ë•Œ Code Interpreterì˜ ì„¸ì…˜ë„ ë‹¤ì‹œ ìƒì„±
        st.session_state.code_interpreter_client = CodeInterpreterClient()
        st.session_state['memory'] = ConversationBufferWindowMemory(
            return_messages=True,
            memory_key="chat_history",
            k=10
        )
        st.session_state.custom_system_prompt = load_system_prompt(
            "./prompt/system_prompt.txt")
        st.session_state.uploaded_files = []


def select_model():
    models = ("GPT-4", "Claude 3.5 Sonnet", "Gemini 1.5 Pro", "GPT-3.5 (not recommended)")
    model = st.sidebar.radio("Choose a model:", models)
    if model == "GPT-3.5 (not recommended)":
        return ChatOpenAI(
            temperature=0, model_name="gpt-3.5-turbo")
    elif model == "GPT-4":
        return ChatOpenAI(
            temperature=0, model_name="gpt-4o")
    elif model == "Claude 3.5 Sonnet":
        return ChatAnthropic(
            temperature=0, model_name="claude-3-5-sonnet-20240620")
    elif model == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(
            temperature=0, model="gemini-1.5-pro-latest")


def create_agent():
	# tools ì™¸ì˜ ë¶€ë¶„ì€ ì´ì „ ì¥ë“¤ê³¼ ì™„ì „íˆ ë™ì¼
    tools = [code_interpreter_tool]
    prompt = ChatPromptTemplate.from_messages([
        ("system", st.session_state.custom_system_prompt),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    llm = select_model()
    agent = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        memory=st.session_state['memory']
    )


def parse_response(response):
    """
	responseì—ì„œ textì™€ image_pathsë¥¼ ì¶”ì¶œ

	responseì˜ ì˜ˆì‹œ
    ===    
	ë¹„íŠ¸ì½”ì¸ì˜ ì¢…ê°€ ì°¨íŠ¸ë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    <img src="./files/file-s4W0rog1pjneOAtWeq21lbDy.png" alt="Bitcoin Closing Price Chart">

	image_pathë¥¼ ì¶”ì¶œí•œ í›„ì—ëŠ” img íƒœê·¸ë¥¼ ì‚­ì œí•´ ë‘”ë‹¤
    """
	# img íƒœê·¸ë¥¼ ì°¾ê¸° ìœ„í•œ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´
    img_pattern = re.compile(r'<img\s+[^>]*?src="([^"]+)"[^>]*?>')

	# img íƒœê·¸ë¥¼ ê²€ìƒ‰í•´ì„œ image_pathsë¥¼ ì¶”ì¶œ
    image_paths = img_pattern.findall(response)

	# img íƒœê·¸ë¥¼ ì‚­ì œí•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ
    text = img_pattern.sub('', response).strip()

    return text, image_paths


def display_content(content):
    import os

    # contentê°€ íŠœí”Œ(text, image_paths)ì¸ì§€ í™•ì¸
    if isinstance(content, tuple):
        text, image_paths = content
    else:
        text, image_paths = parse_response(content)

    st.write(text)

    for image_path in image_paths:
        if os.path.exists(image_path):
            st.image(image_path, caption="")
        else:
            st.warning(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

		
def main():
    init_page()
    csv_upload()
    data_analysis_agent = create_agent()

    for msg in st.session_state['memory'].chat_memory.messages:
        with st.chat_message(msg.type):
            display_content(msg.content)

    if prompt := st.chat_input(placeholder="ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”"):
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            st_cb = StreamlitCallbackHandler(
                st.container(), expand_new_thoughts=True)
            response = data_analysis_agent.invoke(
                {'input': prompt},
            config=RunnableConfig({'callbacks': [st_cb]})
            )
            display_content(response["output"])  # ì´ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ë‘ì…”ë„ ë©ë‹ˆë‹¤			


if __name__ == '__main__':
    main()
