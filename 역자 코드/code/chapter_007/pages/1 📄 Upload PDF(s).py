import fitz  # PyMuPDF
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

###### dotenvë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ì‚­ì œí•´ ì£¼ì„¸ìš” ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


def init_page():
    st.set_page_config(
        page_title="Upload PDF(s)",
        page_icon="ğŸ“„"
    )
    st.sidebar.title("Options")


def init_messages():
    clear_button = st.sidebar.button("Clear DB", key="clear")
    if clear_button and "vectorstore" in st.session_state:
        del st.session_state.vectorstore


def get_pdf_text():
    # file_uploaderë¡œ PDFë¥¼ ì—…ë¡œë“œ í•œë‹¤
    # (file_uploaderì˜ ìì„¸í•œ ì„¤ëª…ì€ 6ì¥ì„ ì°¸ê³ í•˜ì„¸ìš”)
    pdf_file = st.file_uploader(
        label='Upload your PDF ğŸ˜‡',
        type='pdf'  # PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥
    )
    if pdf_file:
        pdf_text = ""
        with st.spinner("Loading PDF ..."):
            # PyMuPDFë¡œ PDFë¥¼ ì½ê¸°
            # (ìì„¸í•œ ì„¤ëª…ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê³µì‹ í˜ì´ì§€ ë“±ì„ ì°¸ê³ í•´ ì£¼ì„¸ìš”)			
            pdf_doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
            for page in pdf_doc:
                pdf_text += page.get_text()

        # RecursiveCharacterTextSplitterë¥¼ ì´ìš©í•´ì„œ ì²­í¬ë¡œ ë¶„ë¦¬í•œë‹¤
        # (ìì„¸í•œ ì„¤ëª…ì€ 6ì¥ì„ ì°¸ê³ í•˜ì„¸ìš”)
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            model_name="text-embedding-3-small",
            # ì ì ˆí•œ ì²­í¬ í¬ê¸°ëŠ” ì§ˆë¬¸ ëŒ€ìƒì¸ PDFì— ë”°ë¼ ë‹¬ë¼ì§€ë¯€ë¡œ ì¡°ì •ì´ í•„ìš”
            # ë„ˆë¬´ í¬ê²Œ í•˜ë©´ ì§ˆë¬¸ì— ë‹µí•  ë•Œ ì—¬ëŸ¬ ì²­í¬ì˜ ì •ë³´ë¥¼ ì°¸ì¡°í•  ìˆ˜ ì—†ìŒ
            # ë°˜ëŒ€ë¡œ ë„ˆë¬´ ì‘ìœ¼ë©´ í•˜ë‚˜ì˜ ì²­í¬ì— ì¶©ë¶„í•œ í¬ê¸°ì˜ ë¬¸ë§¥ì´ ë‹´ê¸°ì§€ ì•ŠìŒ
            chunk_size=500,
            chunk_overlap=0,
        )
        return text_splitter.split_text(pdf_text)
    else:
        return None


def build_vector_store(pdf_text):
    with st.spinner("Saving to vector store ..."):
        if 'vectorstore' in st.session_state:
            st.session_state.vectorstore.add_texts(pdf_text)
        else:
            # ë²¡í„° DBì˜ ì´ˆê¸°í™”ì™€ ë¬¸ì„œ ì¶”ê°€ë¥¼ ë™ì‹œì— ìˆ˜í–‰
            # LangChainì˜ Document Loaderë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì—ëŠ” from_documentsë¥¼ ì‚¬ìš©
            st.session_state.vectorstore = FAISS.from_texts(
                pdf_text,
                OpenAIEmbeddings(model="text-embedding-3-small")
            )

            # FAISSì˜ ê¸°ë³¸ ì„¤ì •ì€ L2 ê±°ë¦¬
            # ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ì„¤ì •í•˜ê³  ì‹¶ì„ ë•ŒëŠ” ì•„ë˜ì™€ ê°™ì´ í•˜ë©´ ë¨
            # from langchain_community.vectorstores.utils import DistanceStrategy
            # st.session_state.vectorstore = FAISS.from_texts(
            #     pdf_text,
            #     OpenAIEmbeddings(model="text-embedding-3-small"),
            #     distance_strategy=DistanceStrategy.COSINE
            # )


def page_pdf_upload_and_build_vector_db():
    st.title("PDF Upload ğŸ“„")
    pdf_text = get_pdf_text()
    if pdf_text:
        build_vector_store(pdf_text)


def main():
    init_page()
    page_pdf_upload_and_build_vector_db()


if __name__ == '__main__':
    main()
