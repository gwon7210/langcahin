
import streamlit as st
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_community.callbacks import StreamlitCallbackHandler

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# custom tools
from tools.search_ddg import search_ddg
from tools.fetch_page import fetch_page

###### dotenvë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ì‚­ì œí•´ ì£¼ì„¸ìš” ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################

CUSTOM_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì¸í„°ë„·ì—ì„œ ì •ë³´ë¥¼ ì¡°ì‚¬í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•´ì„œ ì¡°ì‚¬í•œ ì •ë³´ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”
ì´ë¯¸ ì•Œê³  ìˆëŠ” ê²ƒë§Œì„ ì‚¬ìš©í•´ì„œ ë‹µë³€í•˜ì§€ ë§ê³  ë‹µë³€í•˜ê¸° ì „ì— ê°€ëŠ¥í•˜ë‹¤ë©´ ê²€ìƒ‰ì„ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”.
(ì‚¬ìš©ìê°€ ì½ì„ í˜ì´ì§€ë¥¼ ì§ì ‘ ì§€ì •í•˜ëŠ” ê²ƒ ì²˜ëŸ¼ íŠ¹ë³„í•œ ê²½ìš°ì—ëŠ” ê²€ìƒ‰í•  í•„ìš”ì—†ìŠµë‹ˆë‹¤.)

ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ë§Œìœ¼ë¡œëŠ” ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨ë˜ëŠ” ê²½ìš°ì—ëŠ” ë‹¤ìŒì˜ ë‘ ê°€ì§€ ì˜µì…˜ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.

ê²€ìƒ‰ ê²°ê³¼ì˜ ë§í¬ë¥¼ í´ë¦­í•´ì„œ ê° í˜ì´ì§€ì˜ ì½˜í…ì¸ ì— ì ‘ê·¼í•´ì„œ ë‚´ìš©ì„ ì½ì–´ ë³´ì„¸ìš”.
í•œ í˜ì´ì§€ê°€ ë„ˆë¬´ ê¸´ ê²½ìš°ì—ëŠ” 3ë²ˆ ì´ìƒ ê°€ì ¸ì˜¤ì§€ ë§ˆì„¸ìš” (ë©”ëª¨ë¦¬ì— ë¶€ë‹´ì´ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤).
ê²€ìƒ‰ì–´ë¥¼ ë³€ê²½í•´ì„œ ìƒˆë¡­ê²Œ ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ì„¸ìš”.
ê²€ìƒ‰í•  ë‚´ìš©ì— ë”°ë¼ ì ì ˆí•œ ì–¸ì–´ë¡œ ê²€ìƒ‰ì–´ë¥¼ ë³€ê²½í•´ ì£¼ì„¸ìš”.
  ì˜ˆ: í”„ë¡œê·¸ë˜ë° ê´€ë ¨ ì§ˆë¬¸ì€ ì˜ì–´ë¡œ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ ì ì ˆí•©ë‹ˆë‹¤

ì‚¬ìš©ìëŠ” ë§¤ìš° ë°”ì˜ë©° ë‹¹ì‹ ë§Œí¼ ì—¬ìœ ë¡­ì§€ ì•ŠìŠµë‹ˆë‹¤
ê·¸ëŸ¬ë¯€ë¡œ ì‚¬ìš©ìì˜ ìˆ˜ê³ ë¥¼ ëœê¸° ìœ„í•´ ì§ì ‘ì ì¸ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”

=== ë‚˜ìœ ë‹µë³€ì˜ ì˜ˆ ===
ì´ í˜ì´ì§€ë“¤ì„ ì°¸ê³ í•˜ì„¸ìš”
ì´ í˜ì´ì§€ë“¤ì„ ë³´ë©´ ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
ë‹¤ìŒ í˜ì´ì§€ê°€ ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤

=== ì¢‹ì€ ë‹µë³€ì˜ ì˜ˆ ===
ë‹¤ìŒì€ ìƒ˜í”Œ ì½”ë“œì…ë‹ˆë‹¤. â€” ì—¬ê¸°ì— ìƒ˜í”Œ ì½”ë“œ â€”
ë‹¹ì‹ ì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì€ â€” ì—¬ê¸°ì— ë‹µë³€ â€”

ë‹µë³€ ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ ì°¸ê³ í•œ í˜ì´ì§€ì˜ URLì„ ê¸°ì¬í•´ ì£¼ì„¸ìš”.
(ì‚¬ìš©ìê°€ ë‹µë³€ì„ ê²€ì¦í•  ìˆ˜ ìˆë„ë¡ í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤)

ì‚¬ìš©ìê°€ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”
ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ í•œê¸€ë¡œ ì§ˆë¬¸í–ˆë‹¤ë©´ í•œê¸€ë¡œ, ìŠ¤í˜ì¸ì–´ë¡œ ì§ˆë¬¸í–ˆë‹¤ë©´ ìŠ¤í˜ì¸ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”
"""


def init_page():
    st.set_page_config(
        page_title="Web Browsing Agent",
        page_icon="ğŸ¤—"
    )
    st.header("Web Browsing Agent ğŸ¤—")
    st.sidebar.title("Options")


def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì´ë“  ì§ˆë¬¸í•´ ì£¼ì„¸ìš”ï¼"}
        ]
        st.session_state['memory'] = ConversationBufferWindowMemory(
            return_messages=True,
            memory_key="chat_history",
            k=10
        )

        # ì´ë ‡ê²Œë„ ì“¸ ìˆ˜ ìˆë‹¤
        # from langchain_community.chat_message_histories import StreamlitChatMessageHistory
        # msgs = StreamlitChatMessageHistory(key="special_app_key")
        # st.session_state['memory'] = ConversationBufferMemory(memory_key="history", chat_memory=msgs)


def select_model():
    models = ("GPT-4", "Claude 3.5 Sonnet", "Gemini 1.5 Pro", "GPT-3.5 (not recommended)")
    model = st.sidebar.radio("Choose a model:", models)
    if model == "GPT-3.5 (not recommended)":
        return ChatOpenAI(
            temperature=0, model_name="gpt-3.5-turbo")
    elif model == "GPT-4":
        return ChatOpenAI(
            temperature=0, model_name="gpt-4o")
    elif model == "Claude 3.5 Sonnet":
        return ChatAnthropic(
            temperature=0, model_name="claude-3-5-sonnet-20240620")
    elif model == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(
            temperature=0, model="gemini-1.5-pro-latest")


def create_agent():
    tools = [search_ddg, fetch_page]
    prompt = ChatPromptTemplate.from_messages([
        ("system", CUSTOM_SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    llm = select_model()
    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
    return AgentExecutor.from_agent_and_tools(
        agent=agent,
        tools=tools,
        verbose=True,
        memory=st.session_state['memory']
    )


def main():
    init_page()
    init_messages()
    web_browsing_agent = create_agent()

    for msg in st.session_state['memory'].chat_memory.messages:
        st.chat_message(msg.type).write(msg.content)

    if prompt := st.chat_input(placeholder="2023 FIFA ì—¬ì ì›”ë“œì»µì˜ ìš°ìŠ¹ êµ­ê°€ëŠ”?"):
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            # ì½œë°± í•¨ìˆ˜ ì„¤ì • (ì—ì´ì „íŠ¸ ë™ì‘ ì‹œê°í™”ìš©)
            st_cb = StreamlitCallbackHandler(
                st.container(), expand_new_thoughts=True)

            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            response = web_browsing_agent.invoke(
                {'input': prompt},
                config=RunnableConfig({'callbacks': [st_cb]})
            )
            st.write(response["output"])


if __name__ == '__main__':
    main()
