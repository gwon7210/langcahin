# Github: https://github.com/naotaka1128/llm_app_codes/chapter05/part2/map_reduce.py

import tiktoken
import traceback
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_text_splitters import RecursiveCharacterTextSplitter

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

from urllib.parse import urlparse
from langchain_community.document_loaders import YoutubeLoader  # Youtubeìš©

###### dotenv ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ì‚­ì œí•´ì£¼ì„¸ìš” ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


SUMMARIZE_PROMPT = """ì•„ë˜ ì½˜í…ì¸ ì˜ ë‚´ìš©ì„ ì•½ 300ì ì •ë„ë¡œ ì•Œê¸° ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

========

{content}

========

í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì¤˜!
"""


def init_page():
    st.set_page_config(
        page_title="Youtube Summarizer",
        page_icon="ğŸ¤—"
    )
    st.header("Youtube Summarizer ğŸ¤—")
    st.sidebar.title("Options")


def select_model(temperature=0):
    models = ("GPT-3.5", "GPT-4", "Claude 3.5 Sonnet", "Gemini 1.5 Pro")
    model = st.sidebar.radio("Choose a model:", models)
    if model == "GPT-3.5":
        return ChatOpenAI(
            temperature=temperature,
            model_name="gpt-3.5-turbo"
        )
    elif model == "GPT-4":
        return ChatOpenAI(
            temperature=temperature,
            model_name="gpt-4o"
        )
    elif model == "Claude 3.5 Sonnet":
        return ChatAnthropic(
            temperature=temperature,
            model_name="claude-3-5-sonnet-20240620"
        )
    elif model == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(
            temperature=temperature,
            model="gemini-1.5-pro-latest"
        )


def init_summarize_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_messages([
        ("user", SUMMARIZE_PROMPT),
    ])
    output_parser = StrOutputParser()
    return prompt | llm | output_parser


def init_chain():
    summarize_chain = init_summarize_chain()

    text_splitter = \
        RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            # ëª¨ë¸ì— ë”°ë¼ í† í° ìˆ˜ ê³„ì‚° ë°©ì‹ì´ ë‹¤ë¥´ë¯€ë¡œ model_nameì„ ì§€ì •
            # Claude 3 ì‚¬ìš© ì‹œ ì •í™•í•œ í† í° ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤ëŠ” ì ì— ì£¼ì˜
            model_name="gpt-3.5-turbo",
            # ì²­í¬ í¬ê¸°ëŠ” token ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
            chunk_size=16000,
            chunk_overlap=0,
        )
    text_split = RunnableLambda(
        lambda x: [
            {"content": doc} for doc
            in text_splitter.split_text(x['content'])
        ]
    )
    text_concat = RunnableLambda(
        lambda x: {"content": '\n'.join(x)})
    map_reduce_chain = (
        text_split
        | summarize_chain.map()
        | text_concat
        | summarize_chain
    )

    def route(x):
        encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
        token_count = len(encoding.encode(x["content"]))
        if token_count > 16000:
            return map_reduce_chain
        else:
            return summarize_chain

    chain = RunnableLambda(route)

    return chain


def validate_url(url):
    """ URLì´ ìœ íš¨í•œì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜ """ 
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False


def get_content(url):
    """
    Document:
        - page_content: str
        - metadata: dict
            - source: str
            - title: str
            - description: Optional[str],
            - view_count: int
            - thumbnail_url: Optional[str]
            - publish_date: str
            - length: int
            - author: str
    """
    with st.spinner("Youtube ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        loader = YoutubeLoader.from_youtube_url(
            url,
            add_video_info=False,  # ì¤‘ìš”: ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë”
            language=['ko', 'en']  # í•œêµ­ì–´ ìš°ì„ , ì—†ìœ¼ë©´ ì˜ì–´
        )
        res = loader.load()  # list of `Document` (page_content, metadata)
        try:
            if res:
                content = res[0].page_content
                title = res[0].metadata.get('title', "YouTube Video")
                return f"Title: {title}\n\n{content}"
            else:
                return None
        except:
            st.write(traceback.format_exc())  # ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë‚´ìš©ì„ ì¶œë ¥
            return None


def main():
    init_page()
    chain = init_chain()

    # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ê°ì‹œ
    if url := st.text_input("URL: ", key="input"):
        is_valid_url = validate_url(url)
        if not is_valid_url:
            st.write('Please input valid url')
        else:
            if content := get_content(url):
                st.markdown("## Summary")
                st.write_stream(chain.stream({"content": content}))
                st.markdown("---")
                st.markdown("## Original Text")
                st.write(content)

    # ë¹„ìš©ì„ í‘œì‹œí•˜ë ¤ë©´ 3ì¥ì˜ ì½”ë“œë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”
    # calc_and_display_costs()


if __name__ == '__main__':
    main()
