# Github: https://github.com/naotaka1128/llm_app_codes/chapter05/part1/main.py

import traceback
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

###### dotenvë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì‚­ì œí•˜ì„¸ìš” ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


SUMMARIZE_PROMPT = """ë‹¤ìŒ ì½˜í…ì¸ ì˜ ë‚´ìš©ì„ ì•½ 300ì ì •ë„ë¡œ ì•Œê¸° ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

========

{content}

========

í•œêµ­ì–´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”!
"""


def init_page():
    st.set_page_config(
        page_title="ì›¹ì‚¬ì´íŠ¸ ìš”ì•½ê¸°",
        page_icon="ğŸ¤—"
    )
    st.header("ì›¹ì‚¬ì´íŠ¸ ìš”ì•½ê¸° ğŸ¤—")
    st.sidebar.title("Options")


def select_model(temperature=0):
    models = ("GPT-3.5", "GPT-4", "Claude 3.5 Sonnet", "Gemini 1.5 Pro")
    model = st.sidebar.radio("Choose a model:", models)
    if model == "GPT-3.5":
        return ChatOpenAI(
            temperature=temperature,
            model="gpt-3.5-turbo"
        )
    elif model == "GPT-4":
        return ChatOpenAI(
            temperature=temperature,
            model="gpt-4o"
        )
    elif model == "Claude 3.5 Sonnet":
        return ChatAnthropic(
            temperature=temperature,
            model="claude-3-5-sonnet-20240620"
        )
    elif model == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(
            temperature=temperature,
            model="gemini-1.5-pro-latest"
        )


def init_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_messages([
        ("user", SUMMARIZE_PROMPT),
    ])
    output_parser = StrOutputParser()
    chain = prompt | llm | output_parser
    return chain


def validate_url(url):
    """ URLì´ ìœ íš¨í•œì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜ """
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False


def get_content(url):
    try:
        with st.spinner("Fetching Website ..."):
            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')
            # ê°€ëŠ¥í•œ í•œ ë³¸ë¬¸ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ìš”ì†Œë¥¼ ê°€ì ¸ì˜¨ë‹¤
            if soup.main:
                return soup.main.get_text()
            elif soup.article:
                return soup.article.get_text()
            else:
                return soup.body.get_text()
    except:
        st.write(traceback.format_exc())  # ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš° ì—ëŸ¬ ë‚´ìš©ì„ í‘œì‹œ
        return None


def main():
    init_page()
    chain = init_chain()

    # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ê°ì‹œ
    if url := st.text_input("URL: ", key="input"):
        is_valid_url = validate_url(url)
        if not is_valid_url:
            st.write('Please input valid url')
        else:
            if content := get_content(url):
                st.markdown("## Summary")
                st.write_stream(chain.stream({"content": content}))
                st.markdown("---")
                st.markdown("## Original Text")
                st.write(content)

    # ë¹„ìš©ì„ í‘œì‹œí•˜ë ¤ë©´ 3ì¥ê³¼ ë™ì¼í•œ êµ¬í˜„ì„ ì¶”ê°€í•˜ì„¸ìš”
    # calc_and_display_costs()


if __name__ == '__main__':
    main()
